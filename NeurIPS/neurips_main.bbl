\begin{thebibliography}{10}

\bibitem{alon2016sign}
Noga Alon, Shay Moran, and Amir Yehudayoff.
\newblock Sign rank versus {VC} dimension.
\newblock In {\em Conference on Learning Theory}, pages 47--80, 2016.

\bibitem{alquier2019estimation}
Pierre Alquier, Vincent Cottet, Guillaume Lecu{\'e}, et~al.
\newblock Estimation bounds and sharp oracle inequalities of regularized
  procedures with lipschitz loss functions.
\newblock {\em Annals of Statistics}, 47(4):2117--2144, 2019.

\bibitem{anandkumar2014tensor}
Animashree Anandkumar, Rong Ge, Daniel Hsu, Sham~M Kakade, and Matus Telgarsky.
\newblock Tensor decompositions for learning latent variable models.
\newblock {\em Journal of Machine Learning Research}, 15(1):2773--2832, 2014.

\bibitem{anandkumar2017analyzing}
Animashree Anandkumar, Rong Ge, and Majid Janzamin.
\newblock Analyzing tensor power method dynamics in overcomplete regime.
\newblock {\em Journal of Machine Learning Research}, 18(1):752--791, 2017.

\bibitem{balabdaoui2019least}
Fadoua Balabdaoui, C{\'e}cile Durot, and Hanna Jankowski.
\newblock Least squares estimation in the monotone single index model.
\newblock {\em Bernoulli}, 25(4B):3276--3310, 2019.

\bibitem{bartlett2006convexity}
Peter~L Bartlett, Michael~I Jordan, and Jon~D McAuliffe.
\newblock Convexity, classification, and risk bounds.
\newblock {\em Journal of the American Statistical Association},
  101(473):138--156, 2006.

\bibitem{cai2019nonconvex}
Changxiao Cai, Gen Li, H~Vincent Poor, and Yuxin Chen.
\newblock Nonconvex low-rank tensor completion from noisy data.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  1863--1874, 2019.

\bibitem{chan2014consistent}
Stanley Chan and Edoardo Airoldi.
\newblock A consistent histogram estimator for exchangeable graph models.
\newblock In {\em International Conference on Machine Learning}, pages
  208--216, 2014.

\bibitem{chi2020provable}
Eric~C Chi, Brian~J Gaines, Will~Wei Sun, Hua Zhou, and Jian Yang.
\newblock Provable convex co-clustering of tensors.
\newblock {\em Journal of Machine Learning Research}, 21(214):1--58, 2020.

\bibitem{cohn2013fast}
Henry Cohn and Christopher Umans.
\newblock Fast matrix multiplication using coherent configurations.
\newblock In {\em Proceedings of the twenty-fourth annual ACM-SIAM symposium on
  Discrete algorithms}, pages 1074--1087, 2013.

\bibitem{de2000multilinear}
Lieven De~Lathauwer, Bart De~Moor, and Joos Vandewalle.
\newblock A multilinear singular value decomposition.
\newblock {\em SIAM Journal on Matrix Analysis and Applications},
  21(4):1253--1278, 2000.

\bibitem{de2003nondeterministic}
Ronald De~Wolf.
\newblock Nondeterministic quantum query and communication complexities.
\newblock {\em SIAM Journal on Computing}, 32(3):681--699, 2003.

\bibitem{fan2019online}
Jicong Fan and Madeleine Udell.
\newblock Online high rank matrix completion.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 8690--8698, 2019.

\bibitem{ganti2017learning}
Ravi Ganti, Nikhil Rao, Laura Balzano, Rebecca Willett, and Robert Nowak.
\newblock On learning high dimensional structured single index models.
\newblock In {\em Proceedings of the Thirty-First AAAI Conference on Artificial
  Intelligence}, pages 1898--1904, 2017.

\bibitem{ganti2015matrix}
Ravi~Sastry Ganti, Laura Balzano, and Rebecca Willett.
\newblock Matrix completion under monotonic single index models.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  1873--1881, 2015.

\bibitem{genzel2020robust}
Martin Genzel and Alexander Stollenwerk.
\newblock Robust 1-bit compressed sensing via hinge loss minimization.
\newblock {\em Information and Inference: A Journal of the IMA}, 9(2):361--422,
  2020.

\bibitem{ghadermarzy2018learning}
Navid Ghadermarzy, Yaniv Plan, and Ozgur Yilmaz.
\newblock Learning tensors from partial binary measurements.
\newblock {\em IEEE Transactions on Signal Processing}, 67(1):29--40, 2018.

\bibitem{ghadermarzy2019near}
Navid Ghadermarzy, Yaniv Plan, and {\"O}zg{\"u}r Yilmaz.
\newblock Near-optimal sample complexity for convex tensor completion.
\newblock {\em Information and Inference: A Journal of the IMA}, 8(3):577--619,
  2019.

\bibitem{globerson2007euclidean}
Amir Globerson, Gal Chechik, Fernando Pereira, and Naftali Tishby.
\newblock Euclidean embedding of co-occurrence data.
\newblock {\em Journal of Machine Learning Research}, 8:2265--2295, 2007.

\bibitem{han2020optimal}
Rungang Han, Rebecca Willett, and Anru Zhang.
\newblock An optimal statistical and computational framework for generalized
  tensor estimation.
\newblock {\em arXiv preprint arXiv:2002.11255}, 2020.

\bibitem{hastie2009elements}
Trevor Hastie, Robert Tibshirani, and Jerome Friedman.
\newblock {\em The elements of statistical learning: data mining, inference,
  and prediction}.
\newblock Springer Science \& Business Media, 2009.

\bibitem{he2017kernelized}
Lifang He, Chun-Ta Lu, Guixiang Ma, Shen Wang, Linlin Shen, S~Yu Philip, and
  Ann~B Ragin.
\newblock Kernelized support tensor machines.
\newblock In {\em International Conference on Machine Learning}, pages
  1442--1451. PMLR, 2017.

\bibitem{hillar2013most}
Christopher~J Hillar and Lek-Heng Lim.
\newblock Most tensor problems are {NP}-hard.
\newblock {\em Journal of the ACM (JACM)}, 60(6):45, 2013.

\bibitem{hitchcock1927expression}
Frank~L Hitchcock.
\newblock The expression of a tensor or a polyadic as a sum of products.
\newblock {\em Journal of Mathematics and Physics}, 6(1-4):164--189, 1927.

\bibitem{hong2020generalized}
David Hong, Tamara~G Kolda, and Jed~A Duersch.
\newblock Generalized canonical polyadic tensor decomposition.
\newblock {\em SIAM Review}, 62(1):133--163, 2020.

\bibitem{hore2016tensor}
Victoria Hore, Ana Vi{\~n}uela, Alfonso Buil, Julian Knight, Mark~I McCarthy,
  Kerrin Small, and Jonathan Marchini.
\newblock Tensor decomposition for multiple-tissue gene expression experiments.
\newblock {\em Nature genetics}, 48(9):1094, 2016.

\bibitem{hu2021generalized}
Jiaxin Hu, Chanwoo Lee, and Miaoyan Wang.
\newblock Generalized tensor decomposition with features on multiple modes.
\newblock {\em Journal of Computational and Graphical Statistics}, 0(0):1--15,
  2021.

\bibitem{jain2014provable}
Prateek Jain and Sewoong Oh.
\newblock Provable tensor factorization with missing data.
\newblock In {\em Advances in Neural Information Processing Systems},
  volume~27, pages 1431--1439, 2014.

\bibitem{kolda2009tensor}
Tamara~G Kolda and Brett~W Bader.
\newblock Tensor decompositions and applications.
\newblock {\em SIAM Review}, 51(3):455--500, 2009.

\bibitem{lee2021nonparametric}
Chanwoo Lee, Lexin Li, Hao~Helen Zhang, and Miaoyan Wang.
\newblock Nonparametric trace regression in high dimensions via sign series
  representation.
\newblock {\em arXiv preprint arXiv:2105.01783}, 2021.

\bibitem{pmlr-v119-lee20i}
Chanwoo Lee and Miaoyan Wang.
\newblock Tensor denoising and completion based on ordinal observations.
\newblock In {\em International Conference on Machine Learning}, pages
  5778--5788, 2020.

\bibitem{li2009brain}
Yonghui Li, Yong Liu, Jun Li, Wen Qin, Kuncheng Li, Chunshui Yu, and Tianzi
  Jiang.
\newblock Brain anatomical network and intelligence.
\newblock {\em PLoS Comput Biol}, 5(5):e1000395, 2009.

\bibitem{lovasz2006limits}
L{\'a}szl{\'o} Lov{\'a}sz and Bal{\'a}zs Szegedy.
\newblock Limits of dense graph sequences.
\newblock {\em Journal of Combinatorial Theory, Series B}, 96(6):933--957,
  2006.

\bibitem{montanari2018spectral}
Andrea Montanari and Nike Sun.
\newblock Spectral algorithms for tensor completion.
\newblock {\em Communications on Pure and Applied Mathematics},
  71(11):2381--2425, 2018.

\bibitem{pmlr-v70-ongie17a}
Greg Ongie, Rebecca Willett, Robert~D. Nowak, and Laura Balzano.
\newblock Algebraic variety models for high-rank matrix completion.
\newblock In {\em International Conference on Machine Learning}, pages
  2691--2700, 2017.

\bibitem{robinson1988root}
Peter~M Robinson.
\newblock Root-{N}-consistent semiparametric regression.
\newblock {\em Econometrica: Journal of the Econometric Society},
  56(4):931--954, 1988.

\bibitem{scott2011surrogate}
Clayton Scott.
\newblock Surrogate losses and regret bounds for cost-sensitive classification
  with example-dependent costs.
\newblock In {\em ICML}, 2011.

\bibitem{wang2017bayesian}
Lu~Wang, Daniele Durante, Rex~E Jung, and David~B Dunson.
\newblock Bayesian network--response regression.
\newblock {\em Bioinformatics}, 33(12):1859--1866, 2017.

\bibitem{wang2018learning}
Miaoyan Wang and Lexin Li.
\newblock Learning from binary multiway data: Probabilistic tensor
  decomposition and its statistical optimality.
\newblock {\em Journal of Machine Learning Research}, 21(154):1--38, 2020.

\bibitem{wang2019multiway}
Miaoyan Wang and Yuchen Zeng.
\newblock Multiway clustering via tensor block models.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  713--723, 2019.

\bibitem{xu2018rates}
Jiaming Xu.
\newblock Rates of convergence of spectral methods for graphon estimation.
\newblock In {\em International Conference on Machine Learning}, pages
  5433--5442, 2018.

\bibitem{yuan2016tensor}
Ming Yuan and Cun-Hui Zhang.
\newblock On tensor completion via nuclear norm minimization.
\newblock {\em Foundations of Computational Mathematics}, 16(4):1031--1068,
  2016.

\bibitem{zhang2018tensor}
Anru Zhang and Dong Xia.
\newblock Tensor {SVD}: Statistical and computational limits.
\newblock {\em IEEE Transactions on Information Theory}, 64(11):7311 -- 7338,
  2018.

\bibitem{zhang2017estimating}
Yuan Zhang, Elizaveta Levina, and Ji~Zhu.
\newblock Estimating network edge probabilities by neighbourhood smoothing.
\newblock {\em Biometrika}, 104(4):771--783, 2017.

\bibitem{zhao2015hypergraph}
Yufei Zhao.
\newblock Hypergraph limits: a regularity approach.
\newblock {\em Random Structures \& Algorithms}, 47(2):205--226, 2015.

\end{thebibliography}
